{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai huggingface-hub python-dotenv pandas requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import openai\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set API keys\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "proxycurl_api_key = os.getenv(\"PROXYCURL_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "linkedin_client_id = os.getenv(\"LINKEDIN_CLIENT_ID\")\n",
    "linkedin_client_secret = os.getenv(\"LINKEDIN_CLIENT_SECRET\")\n",
    "linkedin_redirect_uri = os.getenv(\"LINKEDIN_REDIRECT_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hugging Face Inference API\n",
    "hf = InferenceApi(repo_id=\"distilbert-base-uncased-finetuned-sst-2-english\", token=hf_api_key)\n",
    "\n",
    "# Function to extract text from profile sections\n",
    "def extract_text_from_sections(profile, sections):\n",
    "    text = ''\n",
    "    if 'bio' in sections and profile.get('summary'):\n",
    "        text += profile['summary'] + ' '\n",
    "    if 'projects' in sections and profile.get('projects'):\n",
    "        for project in profile['projects']:\n",
    "            if project.get('description'):\n",
    "                text += project['description'] + ' '\n",
    "    if 'experience' in sections and profile.get('experiences'):\n",
    "        for experience in profile['experiences']:\n",
    "            if experience.get('description'):\n",
    "                text += experience['description'] + ' '\n",
    "    if 'skills' in sections and profile.get('skills'):\n",
    "        text += ' '.join(profile['skills']) + ' '\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze traits using OpenAI\n",
    "def analyze_traits(profile):\n",
    "    try:\n",
    "        text = extract_text_from_sections(profile, ['bio', 'projects', 'experience'])\n",
    "        print('Analyzing traits with text:', text)\n",
    "        prompt = f\"Analyze the following text and list the top 7 traits that describe the person professionally: {text}\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        traits = response.choices[0].message['content'].split('\\n').filter(Boolean)\n",
    "        print('Generated Traits:', traits)\n",
    "        return traits\n",
    "    except Exception as e:\n",
    "        print('Error analyzing traits:', str(e))\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate ice breakers using OpenAI\n",
    "def generate_ice_breakers(profile):\n",
    "    try:\n",
    "        prompt = f\"Generate 3 unique and engaging ice breakers based on this LinkedIn profile. The ice breakers should be professional, related to their work experience or skills, and encourage meaningful conversation. Profile: {profile}\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        ice_breakers = response.choices[0].message['content'].split('\\n').filter(Boolean)\n",
    "        print('Generated Ice Breakers:', ice_breakers)\n",
    "        return ice_breakers\n",
    "    except Exception as e:\n",
    "        print('Error generating ice breakers:', str(e))\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate tech skills using OpenAI\n",
    "def generate_tech_skills(profile):\n",
    "    try:\n",
    "        text = extract_text_from_sections(profile, ['bio', 'projects', 'experience'])\n",
    "        print('Generating tech skills with text:', text)\n",
    "        prompt = f\"Analyze the following text and list the top 10 technical skills that the person possesses: {text}\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        tech_skills = response.choices[0].message['content'].split('\\n').filter(Boolean)\n",
    "        print('Generated Tech Skills:', tech_skills)\n",
    "        return tech_skills\n",
    "    except Exception as e:\n",
    "        print('Error generating tech skills:', str(e))\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to enhance skills with emotion analysis using Hugging Face\n",
    "def enhance_skills_with_emotion_analysis(skills):\n",
    "    try:\n",
    "        enhanced_skills = []\n",
    "        for skill in skills:\n",
    "            result = hf(inputs=skill)\n",
    "            print('Emotion Analysis Result for skill:', skill, result)\n",
    "            enhanced_skills.append(f\"{skill} ({result[0]['label']}: {result[0]['score']:.2f})\")\n",
    "        return enhanced_skills\n",
    "    except Exception as e:\n",
    "        print('Error enhancing skills with emotion analysis:', str(e))\n",
    "        return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate job contributions using OpenAI\n",
    "def generate_job_contributions(profile):\n",
    "    try:\n",
    "        prompt = f\"Generate 5 significant job contributions based on this LinkedIn profile. The contributions should highlight the impact and achievements in their roles. Profile: {profile}\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        job_contributions = response.choices[0].message['content'].split('\\n').filter(Boolean)\n",
    "        print('Generated Job Contributions:', job_contributions)\n",
    "        return job_contributions\n",
    "    except Exception as e:\n",
    "        print('Error generating job contributions:', str(e))\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch LinkedIn profile using ProxyCurl\n",
    "def get_linkedin_profile_by_url(linkedin_url):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            'https://nubela.co/proxycurl/api/v2/linkedin',\n",
    "            params={'url': linkedin_url},\n",
    "            headers={'Authorization': f'Bearer {proxycurl_api_key}'}\n",
    "        )\n",
    "        return process_proxycurl_data(response.json())\n",
    "    except Exception as e:\n",
    "        print('Error fetching LinkedIn data from ProxyCurl:', str(e))\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process ProxyCurl data\n",
    "def process_proxycurl_data(data):\n",
    "    return {\n",
    "        'name': f\"{data.get('first_name')} {data.get('last_name')}\",\n",
    "        'headline': data.get('headline'),\n",
    "        'summary': data.get('summary'),\n",
    "        'profileUrl': f\"https://www.linkedin.com/in/{data.get('public_identifier')}/\" if data.get('public_identifier') else None,\n",
    "        'location': data.get('location'),\n",
    "        'industry': data.get('industry'),\n",
    "        'experiences': [{'title': exp.get('title'), 'company': exp.get('company'), 'startDate': exp.get('starts_at'), 'endDate': exp.get('ends_at'), 'description': exp.get('description')} for exp in data.get('experiences', [])],\n",
    "        'education': [{'school': edu.get('school'), 'degree': edu.get('degree_name'), 'fieldOfStudy': edu.get('field_of_study'), 'startDate': edu.get('starts_at'), 'endDate': edu.get('ends_at')} for edu in data.get('education', [])],\n",
    "        'skills': data.get('skills', [])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search LinkedIn profile using Tavily\n",
    "def search_linkedin_profile(name):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            'https://api.tavily.com/search',\n",
    "            params={\n",
    "                'api_key': tavily_api_key,\n",
    "                'query': f'LinkedIn profile of {name}',\n",
    "                'search_depth': 'advanced',\n",
    "                'include_domains': 'linkedin.com'\n",
    "            }\n",
    "        )\n",
    "        return process_linkedin_data(response.json())\n",
    "    except Exception as e:\n",
    "        print('Error fetching LinkedIn data from Tavily:', str(e))\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process LinkedIn data from Tavily\n",
    "def process_linkedin_data(tavily_response):\n",
    "    linkedIn_result = next((result for result in tavily_response.get('results', []) if 'linkedin.com/in/' in result.get('url', '')), None)\n",
    "    if not linkedIn_result:\n",
    "        raise ValueError('LinkedIn profile not found')\n",
    "    return {\n",
    "        'name': linkedIn_result['title'].split(' | ')[0],\n",
    "        'headline': linkedIn_result['title'].split(' | ')[1],\n",
    "        'summary': linkedIn_result['snippet'],\n",
    "        'profileUrl': linkedIn_result['url']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample LinkedIn profile data for testing\n",
    "sample_profile = {\n",
    "    'summary': 'Experienced data scientist with a demonstrated history of working in the tech industry.',\n",
    "    'projects': [{'description': 'Developed a machine learning model for predicting customer churn.'}],\n",
    "    'experiences': [{'description': 'Worked as a data scientist at a leading tech company.'}],\n",
    "    'skills': ['Python', 'Machine Learning', 'Data Analysis']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions\n",
    "traits = analyze_traits(sample_profile)\n",
    "print(\"Traits:\", traits)\n",
    "\n",
    "tech_skills = generate_tech_skills(sample_profile)\n",
    "print(\"Tech Skills:\", tech_skills)\n",
    "\n",
    "enhanced_tech_skills = enhance_skills_with_emotion_analysis(tech_skills)\n",
    "print(\"Enhanced Tech Skills:\", enhanced_tech_skills)\n",
    "\n",
    "job_contributions = generate_job_contributions(sample_profile)\n",
    "print(\"Job Contributions:\", job_contributions)\n",
    "\n",
    "# Fetch and display LinkedIn profile data from ProxyCurl\n",
    "linkedin_profile = get_linkedin_profile_by_url('https://www.linkedin.com/in/sample-profile/')\n",
    "print(\"LinkedIn Profile (ProxyCurl):\", linkedin_profile)\n",
    "\n",
    "# Search and display LinkedIn profile data from Tavily\n",
    "searched_profile = search_linkedin_profile('Sample Name')\n",
    "print(\"Searched LinkedIn Profile (Tavily):\", searched_profile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
